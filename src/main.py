# main.py (æ›´æ–°ç‰ˆæœ¬ - ä¸­æ–‡è¾“å‡º)
import os
import torch
import sys
import argparse

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.config import Config
from src.audio_preprocessor import AudioDataPreprocessor
from src.model_builder import create_improved_classifier
from src.advanced_models import create_advanced_classifier, create_simplified_classifier
from src.model_trainer import AdvancedModelTrainer
from src.model_manager import model_manager
from src.utils import download_dataset, plot_training_history, analyze_model_performance

def setup_device():
    """è®¾ç½®è®­ç»ƒè®¾å¤‡"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸ‰ ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print("âŒ ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
    return device

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='AIéŸ³é¢‘åˆ†æä¸è‡ªåŠ¨æ‰’è°±ç³»ç»Ÿ')
    parser.add_argument('--no-cache', action='store_true', 
                       help='ä¸ä½¿ç”¨ç¼“å­˜ï¼Œé‡æ–°é¢„å¤„ç†æ•°æ®')
    parser.add_argument('--resume', type=str, default=None,
                       help='ä»æŒ‡å®šæ¨¡å‹ç»§ç»­è®­ç»ƒ')
    parser.add_argument('--epochs', type=int, default=Config.EPOCHS,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--no-resume', action='store_true',
                       help='å¼ºåˆ¶ä»å¤´å¼€å§‹è®­ç»ƒï¼Œå¿½ç•¥ç°æœ‰æ¨¡å‹')
    parser.add_argument('--basic-model', action='store_true',
                       help='ä½¿ç”¨åŸºç¡€æ¨¡å‹è€Œä¸æ˜¯é«˜çº§æ¨¡å‹')
    parser.add_argument('--no-augmentation', action='store_true',
                       help='ç¦ç”¨æ•°æ®å¢å¼º')
    parser.add_argument('--model-type', type=str, default='simplified', 
                       choices=['basic', 'advanced', 'simplified', 'all'],
                       help='ä½¿ç”¨çš„æ¨¡å‹ç±»å‹ (basic, advanced, simplified, all)')
    parser.add_argument('--train-all', action='store_true',
                       help='è®­ç»ƒæ‰€æœ‰æ¨¡å‹ç±»å‹')
    return parser.parse_args()

def create_model(model_type, input_shape, num_classes, device):
    """æ ¹æ®ç±»å‹åˆ›å»ºæ¨¡å‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡"""
    if model_type == 'basic':
        model = create_improved_classifier(input_shape, num_classes)
    elif model_type == 'advanced':
        try:
            model = create_advanced_classifier(input_shape, num_classes)
        except Exception as e:
            print(f"é«˜çº§æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            print("å›é€€åˆ°ç¨³å®šé«˜çº§æ¨¡å‹")
            model = create_stable_advanced_classifier(input_shape, num_classes)
    elif model_type == 'simplified':
        model = create_simplified_classifier(input_shape, num_classes)
    elif model_type == 'stable_advanced':
        model = create_stable_advanced_classifier(input_shape, num_classes)
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}")
    
    # ç«‹å³ç§»åŠ¨åˆ°è®¾å¤‡
    model = model.to(device)
    print(f"âœ… {model_type}æ¨¡å‹å·²åˆ›å»ºå¹¶ç§»åŠ¨åˆ°{device}")
    
    return model


def train_single_model(model_type, train_loader, val_loader, test_loader, preprocessor, device, args):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    print(f"\n{'='*50}")
    print(f"è®­ç»ƒ {model_type} æ¨¡å‹")
    print(f"{'='*50}")
    
    # è·å–è¾“å…¥å½¢çŠ¶
    for data, _ in train_loader:
        input_shape = data.shape[1:]  # (1, 128, 130)
        break
    
    print(f"è¾“å…¥å½¢çŠ¶: {input_shape}")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹å¹¶ç«‹å³ç§»åŠ¨åˆ°è®¾å¤‡
    model = create_model(model_type, input_shape, len(preprocessor.label_encoder.classes_), device)
    
    # ç»Ÿè®¡å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = AdvancedModelTrainer(model, preprocessor, device, model_type=model_type)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¢å¤è®­ç»ƒ
    resume_model = not args.no_resume
    if resume_model:
        load_success, checkpoint = model_manager.load_model(model, model_type, device)
        if load_success and checkpoint and 'history' in checkpoint:
            trainer.history = checkpoint['history']
            print(f"æ¢å¤è®­ç»ƒå†å²ï¼Œå·²è®­ç»ƒ {len(trainer.history['train_loss'])} ä¸ªå‘¨æœŸ")
            print(f"âœ… {model_type}æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç»§ç»­è®­ç»ƒ...")
        else:
            print(f"âœ… ä»å¤´å¼€å§‹è®­ç»ƒ{model_type}æ¨¡å‹...")
    else:
        print(f"âœ… å¼ºåˆ¶ä»å¤´å¼€å§‹è®­ç»ƒ{model_type}æ¨¡å‹...")
    
    # è®­ç»ƒæ¨¡å‹
    history = trainer.train(train_loader, val_loader, epochs=args.epochs, 
                           patience=Config.EARLY_STOPPING_PATIENCE)
    
    # è¯„ä¼°æ¨¡å‹
    test_loss, test_acc = trainer.evaluate(test_loader)
    
    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    trainer.save_model()
    
    return test_acc, history

def setup_device():
    """è®¾ç½®è®­ç»ƒè®¾å¤‡ - å¢åŠ å†…å­˜ç›‘æ§"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"ğŸ‰ ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
        # æ‰“å°GPUå†…å­˜ä¿¡æ¯
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        device = torch.device('cpu')
        print("âŒ ä½¿ç”¨CPUè¿›è¡Œè®­ç»ƒ")
    return device

def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    
    print("=== AIéŸ³é¢‘åˆ†æä¸è‡ªåŠ¨æ‰’è°±ç³»ç»Ÿ - å¤šç‰ˆæœ¬æ¨¡å‹ ===")
    print(f"ä½¿ç”¨ç¼“å­˜: {not args.no_cache}")
    print(f"æ¨¡å‹ç±»å‹: {args.model_type}")
    print(f"ä½¿ç”¨æ•°æ®å¢å¼º: {not args.no_augmentation}")
    print(f"åŒæ—¶ä¿å­˜å¤šä¸ªç‰ˆæœ¬: {Config.SAVE_MULTIPLE_VERSIONS}")
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    available_models = model_manager.get_available_models()
    if available_models:
        print(f"å·²å­˜åœ¨çš„æ¨¡å‹: {', '.join(available_models)}")
    else:
        print("æ²¡æœ‰æ‰¾åˆ°å·²è®­ç»ƒçš„æ¨¡å‹")
    
    # 1. åˆå§‹åŒ–é…ç½®
    print("\n1. åˆå§‹åŒ–é…ç½®...")
    Config.create_directories()
    
    # 2. è®¾ç½®è®¾å¤‡
    print("2. æ£€æŸ¥ç¡¬ä»¶é…ç½®...")
    device = setup_device()
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # 3. æ•°æ®é¢„å¤„ç†
    print("3. æ•°æ®é¢„å¤„ç†...")
    preprocessor = AudioDataPreprocessor(use_cache=not args.no_cache)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼Œå¯é€‰æ•°æ®å¢å¼º
    use_augmentation = not args.no_augmentation and Config.USE_DATA_AUGMENTATION
    train_loader, val_loader, test_loader, num_classes = preprocessor.create_data_loaders(
        use_cache=not args.no_cache, 
        augment=use_augmentation
    )
    
    print(f"ç±»åˆ«æ•°é‡: {num_classes}")
    
    # ç¡®å®šè¦è®­ç»ƒçš„æ¨¡å‹ç±»å‹
    if args.model_type == 'all' or args.train_all:
        model_types = ['basic', 'simplified', 'advanced']
    else:
        model_types = [args.model_type]
    
    # è®­ç»ƒç»“æœç»Ÿè®¡
    results = {}
    
    # 4. è®­ç»ƒæ¨¡å‹
    for model_type in model_types:
        try:
            test_acc, history = train_single_model(
                model_type, train_loader, val_loader, test_loader, 
                preprocessor, device, args
            )
            results[model_type] = {
                'test_accuracy': test_acc,
                'history': history
            }
            
            # å¯è§†åŒ–ç»“æœ
            print(f"8. ç”Ÿæˆ{model_type}æ¨¡å‹å¯è§†åŒ–ç»“æœ...")
            plot_training_history(
                history['train_loss'], history['val_loss'],
                history['train_acc'], history['val_acc'],
                os.path.join(Config.OUTPUT_DIR, f'training_curves_{model_type}.png'),
                show_plot=False  # æ·»åŠ è¿™ä¸ªå‚æ•°
            )
            
            # æ€§èƒ½åˆ†æï¼ˆåªåœ¨æœ€åä¸€ä¸ªæ¨¡å‹ä¸Šæ‰§è¡Œï¼Œé¿å…é‡å¤ï¼‰
            if model_type == model_types[-1]:
                print("9. æ€§èƒ½åˆ†æ...")
                # é‡æ–°åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œè¯„ä¼°
                best_model = create_model(model_type, train_loader.dataset[0][0].shape, num_classes)
                best_model = best_model.to(device)
                load_success, _ = model_manager.load_model(best_model, model_type, device)
                
                if load_success:
                    analyze_model_performance(
                        best_model, test_loader, preprocessor.label_encoder, device, Config.OUTPUT_DIR
                    )
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒ{model_type}æ¨¡å‹æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # 5. è¾“å‡ºè®­ç»ƒæ€»ç»“
    print("\n" + "="*60)
    print("è®­ç»ƒæ€»ç»“")
    print("="*60)
    
    for model_type, result in results.items():
        print(f"{model_type:>10}æ¨¡å‹: æµ‹è¯•å‡†ç¡®ç‡ = {result['test_accuracy']:.4f}")
    
    print(f"\næ¨¡å‹ä¿å­˜ä½ç½®: {Config.MODEL_DIR}")
    print(f"è¾“å‡ºæ–‡ä»¶ä½ç½®: {Config.OUTPUT_DIR}")
    
    # æ˜¾ç¤ºæœ€ç»ˆå¯ç”¨çš„æ¨¡å‹
    final_models = model_manager.get_available_models()
    print(f"æœ€ç»ˆå¯ç”¨æ¨¡å‹: {', '.join(final_models)}")

if __name__ == "__main__":
    main()